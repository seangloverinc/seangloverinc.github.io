---
layout: post
title: Extracting noun phrases with contextual relevance in .NET using OpenNLP
date: 2012-08-29 07:43:45.000000000 -04:00
categories:
- Natural Language Processing
tags:
- Natural Language Processing
- noun phrase
- OpenNLP
status: publish
type: post
published: true
meta:
  dsq_thread_id: '822869950'
  _syntaxhighlighter_encoded: '1'
  _edit_last: '1'
author:
  login: wladek
  email: wladek@gmail.com
  display_name: Sean Glover
  first_name: Sean
  last_name: Glover
excerpt: !ruby/object:Hpricot::Doc
  options: {}
---
<p>A few months ago I was working on a project that had a word cloud-like feature. A word cloud is an interesting way to visually represent a popular theme or topic. I had a dataset of user reviews from another project that we wanted to parse and use. This began my first exposure to Natural Language Processing (NLP) and other advanced text analytics tools.</p>
<h2>Notes from an NLP spike</h2>
<p>I started by extracting nouns from our dataset and calculating frequency. This resulted in a list of top used terms, but unlike a tag cloud implementation for a blog, the results were not always relevant. I needed a way to capture the theme of a sentence, sum up all the reviews with the same theme, and then present the top themes to the user. Think of a yelp user review and its core positive or negative theme. Then calculate how many other user reviews have the same theme, i.e. reviews for a pub that often mentioned its "great patio". It wasn't long before I started reading about NLP tools and in particular, Part of Speech (PoS) analyzers. I started learning the vocabulary of the NLP world such as N-grams, sentence chunking, and most importantly, noun phrases. Noun phrases contained two or more words (including a noun) which provide some contextual relevance to the theme of the sentence.</p>
<p>Below is a more formal definition of a noun phrase with an example.</p>
<blockquote><p>A word group with a noun or pronoun as its head. The noun head can be accompanied by modifiers, determiners (such as the, a, her), and/or complements.</p>
<p>A noun phrase (often abbreviated as NP) most commonly functions as a subject, object, or complement.</p>
<p>"<strong>The wells and water table</strong> had been polluted by <strong>chemical pesticides and fertilizers</strong> that leached into <strong>the earth</strong> and were washed by rain into <strong>the creeks</strong>, where <strong>the stunned fish</strong> were scavenged by <strong>the ospreys</strong>."<br />
(Peter Matthiessen, Men's Lives, 1986)</p>
<p>- <a href="http://grammar.about.com/od/mo/g/nounphraseterm.htm">noun phrase, About.com</a></p></blockquote>
<p>Identifying noun phrases is not a trivial task. I started reading up on big open source projects in the NLP game like <a href="http://opennlp.apache.org/">OpenNLP</a> (Java), <a href="http://nltk.org/">NLTK</a> (python), and <a href="http://alias-i.com/lingpipe/">LingPipe</a> (Java). I also found a great deal of smaller analytics tools and parsers, but none seemed advanced enough to really capture the essence of a noun phrase or theme of a sentence. It was then that a colleague pointed me in the direction of SQL Server Integration Services (SSIS) text analytics transformations. Most notably, the <a href="http://msdn.microsoft.com/en-us/library/ms141809.aspx">Term Extraction</a> and <a href="http://msdn.microsoft.com/en-us/library/ms137850.aspx">Term Lookup</a> transformations. A PoC quickly demonstrated that these transformations were an efficient and scalable way to extract noun phrases. It was very simple to configure and get up and running (if you don't mind using BIDS, *shudder*). I was able to extract meaningful noun phrases with a high degree of accuracy. However, it had a number of limitations.</p>
<ul>
<li>It's an SSIS package, great for parsing text after-the-fact, but not in real time.</li>
<li>It requires a SQL Server enterprise license ($$).</li>
<li>It only supports English with no plans of supporting other languages.</li>
</ul>
<p>Ideally, I wanted to replace the SSIS package with an in-process solution, but unfortunately there are limited text analytics tools available for the .NET community. There are a few options. <a href="http://sharpnlp.codeplex.com/">SharperNLP</a> is a C# port of OpenNLP. It had a brief flurry of activity in 2006, but not much since then. Here are some notes from someone who attempted to integrate with NLTK in a .NET implementation using IronPython: <a href="http://blog.samibadawi.com/2010/03/open-source-nlp-in-c-35-using-nltk.html">Open Source NLP in C# 3.5 using NLTK</a>.</p>
<p>I even put the question to StackOverflow in a question titled <a href="http://stackoverflow.com/questions/11320776/extracting-terms-with-contextual-relevance-noun-phrases-from-text-in-a-net-pr">"Extracting terms with contextual relevance (noun phrases) from text in a .NET project"</a>. An answer on this question revealed an option I hadn't considered. Although I didn't want to have an IPC (Inter-Process Communication) layer I started thinking about setting up a dedicated full text analytics server with <a href="http://lucene.apache.org/solr/">Apache Solr</a>. As of this writing there is a push to get <a href="http://wiki.apache.org/solr/OpenNLP">OpenNLP analytics and filters committed to Solr</a> itself, but it still requires a patch (<a href="https://issues.apache.org/jira/browse/LUCENE-2899">LUCENE-2899</a>) and a fairly lengthy configuration process to get up and running.</p>
<h2>A viable .NET implementation</h2>
<p>Eventually I came across a wiki article entitled "<a href="https://cwiki.apache.org/OPENNLP/a-quick-guide-to-using-opennlp-from-net.html">A quick guide to using OpenNLP from .NET</a>" that introduced me to a remarkable project called <a href="http://www.ikvm.net/index.html">IKVM.NET</a>. After generating a shiney new .NET OpenNLP assembly with the steps provided I was able to use the OpenNLP namespaces with ease in my project.</p>
<p>The first step in using the parsers in OpenNLP was to instantiate a model using Java streams. I created a base class for my NounPhraseParser with a utility method to help load these models.</p>
<p>[sourcecode language="csharp"]<br />
using System;<br />
using System.Collections.Generic;<br />
using System.IO;<br />
using System.Linq;</p>
<p>namespace OpenNLP.NET.PoC<br />
{<br />
    public class AbstractNounPhraseAdapter<br />
    {<br />
        protected readonly string ModelsPath;</p>
<p>        /// &lt;summary&gt;<br />
        /// A path to the directory where the OpenNLP models are located.<br />
        /// &lt;/summary&gt;<br />
        protected AbstractNounPhraseAdapter(string modelsPath)<br />
        {<br />
            ModelsPath = modelsPath;<br />
        }</p>
<p>        /// &lt;summary&gt;<br />
        /// Return the OpenNLP analyzer given its model type (M), the type of the analyzer (T), the filename<br />
        /// of the model (i.e. en-maxent.bin) and a path to where the Models are lcoated (ModelsPath).<br />
        /// &lt;/summary&gt;<br />
        public T ResolveOpenNlpTool(string modelPath)<br />
            where M : class<br />
            where T : class<br />
        {<br />
            var modelStream = new java.io.FileInputStream(Path.Combine(ModelsPath, modelPath));</p>
<p>            M model;<br />
            try<br />
            {<br />
                model = (M)Activator.CreateInstance(typeof(M), modelStream);<br />
            }<br />
            finally<br />
            {<br />
                if (modelStream != null)<br />
                {<br />
                    modelStream.close();<br />
                }<br />
            }</p>
<p>            return (T)Activator.CreateInstance(typeof(T), model);<br />
        }</p>
<p>        /// &lt;summary&gt;<br />
        /// Functions to run after PoS parsing to determine if the noun phrase should be returned.<br />
        /// &lt;/summary&gt;<br />
        public IEnumerable&lt;Func&gt; PostProcessingFilters { get; set; }</p>
<p>        protected bool ValidNounPhrase(string nounPhrase)<br />
        {<br />
            return PostProcessingFilters == null ||<br />
                    PostProcessingFilters.Aggregate(true, (current, filter) =&gt; current &amp;&amp; filter.Invoke(nounPhrase));<br />
        }<br />
    }<br />
}<br />
[/sourcecode]</p>
<p>The guts of my PosNounPhraseParser itself contains a parsing method named GetNounPhrases which is based on code by Sujit Pal described in his blog posting entitled "<a href="http://sujitpal.blogspot.ca/2011/08/uima-noun-phrase-pos-annotator-using.html">An UIMA Noun Phrase POS Annotator using OpenNLP</a>".</p>
<p>[sourcecode language="csharp"]<br />
using System;<br />
using System.Collections.Generic;<br />
using opennlp.tools.chunker;<br />
using opennlp.tools.postag;<br />
using opennlp.tools.sentdetect;<br />
using opennlp.tools.tokenize;</p>
<p>namespace OpenNLP.NET.PoC<br />
{<br />
    /// &lt;summary&gt;<br />
    /// Ported from Java implementation by Sujit Pal<br />
    /// http://sujitpal.blogspot.ca/2011/08/uima-noun-phrase-pos-annotator-using.html<br />
    /// &lt;/summary&gt;<br />
    public class PosNounPhraseParser : AbstractNounPhraseAdapter, INounPhraseParser<br />
    {<br />
        public PosNounPhraseParser(string modelsPath) : base(modelsPath) { }</p>
<p>        private static SentenceDetector _sentenceDetector;<br />
        private SentenceDetector GetSentenceDetector()<br />
        {<br />
            return _sentenceDetector ?? (_sentenceDetector = ResolveOpenNlpTool(&quot;en-sent.bin&quot;));<br />
        }</p>
<p>        private static POSTagger _posTagger;<br />
        private POSTagger GetPosTagger()<br />
        {<br />
            return _posTagger ?? (_posTagger = ResolveOpenNlpTool(&quot;en-pos-maxent.bin&quot;));<br />
        }</p>
<p>        private static Tokenizer _tokenizer;<br />
        private Tokenizer GetTokenizer()<br />
        {<br />
            return _tokenizer ?? (_tokenizer = ResolveOpenNlpTool(&quot;en-token.bin&quot;));<br />
        }</p>
<p>        private static Chunker _chunker;<br />
        private Chunker GetChunker()<br />
        {<br />
            return _chunker ?? (_chunker = ResolveOpenNlpTool(&quot;en-chunker.bin&quot;));<br />
        }</p>
<p>        public void WarmUpModels()<br />
        {<br />
            GetSentenceDetector();<br />
            GetPosTagger();<br />
            GetTokenizer();<br />
            GetChunker();<br />
        }</p>
<p>        public IList&lt;string&gt; GetNounPhrases(string sourceText)<br />
        {<br />
            if (string.IsNullOrWhiteSpace(sourceText)) throw new ArgumentNullException(&quot;sourceText&quot;);</p>
<p>            var nounPhrases = new List&lt;string&gt;();</p>
<p>            // return an array of start and end indexes that identify sentences<br />
            var sentenceSpans = GetSentenceDetector().sentPosDetect(sourceText);<br />
            foreach (var sentenceSpan in sentenceSpans)<br />
            {<br />
                // retrieve the actual sentence from the source text<br />
                var sentence = sentenceSpan.getCoveredText(sourceText).toString();<br />
                var start = sentenceSpan.getStart();</p>
<p>                // return an array of start and end indexes that identify various<br />
                // tokens/tags in the sentence (i.e. noun phrases, verb phrases, etc)<br />
                var tokenSpans = GetTokenizer().tokenizePos(sentence);<br />
                var tokens = new string[tokenSpans.Length];<br />
                for (var i = 0; i &lt; tokens.Length; i++)<br />
                {<br />
                    tokens[i] = tokenSpans[i].getCoveredText(sentence).toString();<br />
                }<br />
                var tags = GetPosTagger().tag(tokens);</p>
<p>                // return an array of chunks that contain tag types and start/end indexes<br />
                // for the chunk in the source text<br />
                var chunks = GetChunker().chunkAsSpans(tokens, tags);</p>
<p>                foreach (var chunk in chunks)<br />
                {<br />
                    // filter out everything but noun phrases<br />
                    if (chunk.getType() != &quot;NP&quot;) continue;</p>
<p>                    var chunkStart = start + tokenSpans[chunk.getStart()].getStart();<br />
                    var chunkEnd = start + tokenSpans[chunk.getEnd() - 1].getEnd();</p>
<p>                    // extract the noun phrase<br />
                    var nounPhrase = sourceText.Substring(chunkStart, chunkEnd - chunkStart);</p>
<p>                    // run post processing functions to determine if this noun phrase<br />
                    // is suitable for our purposes (defined by caller)<br />
                    if (!ValidNounPhrase(nounPhrase)) continue;</p>
<p>                    nounPhrases.Add(nounPhrase);<br />
                }<br />
            }<br />
            return nounPhrases;<br />
        }<br />
    }<br />
}<br />
[/sourcecode]</p>
<p>And finally, a test that demonstrates the setup of my PosNounPhraseParser over the example sentence mentioned earlier in the definition of a noun phrase.</p>
<p>[sourcecode language="csharp"]<br />
using System;<br />
using System.Collections.Generic;<br />
using System.Diagnostics;<br />
using System.Linq;<br />
using NUnit.Framework;</p>
<p>namespace OpenNLP.NET.PoC<br />
{<br />
    [TestFixture]<br />
    public class PosNounPhraseParserTests<br />
    {<br />
        [Test]<br />
        public void PosNounPhraseParser_GetNounPhrases_Extract_Noun_Phrases_From_Sentence()<br />
        {<br />
            string _modelPath = @&quot;C:\Development\NLPForDotNET\lib\opennlp-models-1.5\&quot;;</p>
<p>            // arrange<br />
            var nounPhraseAdapter = new PosNounPhraseParser(_modelPath)<br />
            {<br />
                PostProcessingFilters = new List&lt;Func&gt;<br />
                                                                        {<br />
                                                                            // more than two words<br />
                                                                            (nounPhrase =&gt; nounPhrase.Split(&quot; &quot;.ToCharArray()).Count() &gt; 1),<br />
                                                                            // character stop list<br />
                                                                            (nounPhrase =&gt;<br />
                                                                             !(nounPhrase.Contains(&quot;.&quot;) ||<br />
                                                                               nounPhrase.Contains(&quot;\&quot;&quot;) ||<br />
                                                                               nounPhrase.Contains(&quot;,&quot;) ||<br />
                                                                               nounPhrase.Contains(&quot;”&quot;) ||<br />
                                                                               nounPhrase.Contains(&quot;“&quot;) ||<br />
                                                                               nounPhrase.Contains(&quot;;&quot;)))<br />
                                                                        }<br />
            };</p>
<p>            nounPhraseAdapter.WarmUpModels();</p>
<p>            var stopwatch = new Stopwatch();<br />
            stopwatch.Start();</p>
<p>            // act<br />
            var actualNounPhrases = nounPhraseAdapter<br />
                .GetNounPhrases(&quot;The wells and water table had been polluted by chemical pesticides and fertilizers that leached into the earth and were washed by rain into the creeks, where the stunned fish were scavenged by the ospreys.&quot;)<br />
                .ToArray();</p>
<p>            stopwatch.Stop();</p>
<p>            Debug.WriteLine(&quot;Total time: {0}&quot;, stopwatch.Elapsed);</p>
<p>            // assert<br />
            Assert.Contains(&quot;The wells and water table&quot;, actualNounPhrases);<br />
            Assert.Contains(&quot;chemical pesticides and fertilizers&quot;, actualNounPhrases);<br />
            Assert.Contains(&quot;the earth&quot;, actualNounPhrases);<br />
            Assert.Contains(&quot;the creeks&quot;, actualNounPhrases);<br />
            Assert.Contains(&quot;the stunned fish&quot;, actualNounPhrases);<br />
            Assert.Contains(&quot;the ospreys&quot;, actualNounPhrases);<br />
        }<br />
    }<br />
}<br />
[/sourcecode]</p>
<h2>Conclusion</h2>
<p>I think this project worked out remarkably well. I don't know if I'll attempt to use something like this in a production environment, but if nothing else it was a very enlightening foray into the interesting world of Natural Language Processing. There are many other subjects in this area that I would like to explore, such as Sentiment Analysis and ways to identify subjects of significance in large bodies of text. As the IBM Watson project demonstrated to us not too long ago, this is a young field with staggering potential. The current trajectory of research along with significant advances in computation capability suggest it won't be long before we can communicate with computers/information systems as easily as if you were talking to your best friend.</p>
<p>If you wish to use the solution I've demonstrated in this post please make your own determination on whether it's acceptable for your project. I'm no expert in licensing, but I've cited all my sources where available so that the reader can execute their own due diligence.</p>
